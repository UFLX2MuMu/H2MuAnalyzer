// Class: ReadBDTG_AWB_lite
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDTG_AWB_lite
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.12/07       [396295]
Creator        : abrinke1
Date           : Thu Jul  4 07:55:43 2019
Host           : Linux cmsbuild92.cern.ch 2.6.32-696.30.1.el6.x86_64 #1 SMP Tue May 22 06:09:36 CEST 2018 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/user/a/abrinke1/HiggsToMuMu/2018/CMSSW_10_2_11_patch1/src/H2MuAnalyzer/TrainMVA
Training events: 154963
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "2" [Max depth of the decision tree allowed]
nCuts: "20" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "Grad" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
UseBaggedBoost: "True" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e-01" [Learning rate for GradBoost algorithm]
BaggedSampleFraction: "5.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
AdaBoostBeta: "5.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "4" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
NegWeightTreatment: "pray" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
SeparationType: "giniindex" [Separation criterion for node splitting]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "5.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 18
H_pair_pt                     H_pair_pt                     H_pair_pt                     H_pair_pt                                                       'F'    [0.174321591854,1592.23571777]
OS_pair_mass                  OS_pair_mass                  OS_pair_mass                  OS_pair_mass                                                    'F'    [12.0022649765,1810.3840332]
nEles                         nEles                         nEles                         Number of electrons                                             'I'    [0,1]
muH1_eta_abs                  muH1_eta_abs                  muH1_eta_abs                  |#eta| #mu1 from Higgs                                          'F'    [4.18702620664e-06,2.39995646477]
muH2_eta_abs                  muH2_eta_abs                  muH2_eta_abs                  |#eta| #mu2 from Higgs                                          'F'    [2.60819365394e-06,2.39999866486]
muSS_muOS_dR                  muSS_muOS_dR                  muSS_muOS_dR                  muSS_muOS_dR                                                    'F'    [0.171248823404,5.13359117508]
muSS_OS_pair_dR               muSS_OS_pair_dR               muSS_OS_pair_dR               muSS_OS_pair_dR                                                 'F'    [0.0193049702793,7.22482681274]
lep_pt                        lep_pt                        lep_pt                        lep_pt                                                          'F'    [10.00050354,1104.6217041]
muSS_pt                       muSS_pt                       muSS_pt                       muSS_pt                                                         'F'    [10.0215930939,1146.91748047]
nJetsCent                     nJetsCent                     nJetsCent                     nJetsCent                                                       'I'    [1,15]
nJetsCent30                   nJetsCent30                   nJetsCent30                   nJetsCent30                                                     'I'    [0,13]
nJetsCent40                   nJetsCent40                   nJetsCent40                   nJetsCent40                                                     'I'    [0,11]
nBJetsLoose                   nBJetsLoose                   nBJetsLoose                   nBJetsLoose                                                     'I'    [1,7]
nBJetsMed                     nBJetsMed                     nBJetsMed                     nBJetsMed                                                       'I'    [0,6]
lep_MET_MT                    lep_MET_MT                    lep_MET_MT                    lep_MET_MT                                                      'F'    [0.000542099878658,1189.62780762]
lep_MHT_MT                    lep_MHT_MT                    lep_MHT_MT                    lep_MHT_MT                                                      'F'    [4.15259200963e-05,1138.2109375]
muSS_MET_MT                   muSS_MET_MT                   muSS_MET_MT                   muSS_MET_MT                                                     'F'    [0.00372117804363,1599.34997559]
muSS_MHT_MT                   muSS_MHT_MT                   muSS_MHT_MT                   muSS_MHT_MT                                                     'F'    [9.12741525099e-05,1757.95397949]
NSpec 9
samp_ID                       samp_ID                       samp_ID                       Sample ID                                                       'F'    [-26,38]
event                         event                         event                         Event number                                                    'F'    [3,170579920]
event_wgt                     event_wgt                     event_wgt                     Per-event scale factors                                         'F'    [-6.37165927887,18.4841747284]
samp_wgt                      samp_wgt                      samp_wgt                      Xsec x lumi for sample                                          'F'    [2.80000003841e-05,3.92017388344]
lepMVA_wgt                    lepMVA_wgt                    lepMVA_wgt                    lepMVA efficiency SF                                            'F'    [0.416317880154,1.15934419632]
total_wgt                     total_wgt                     total_wgt                     Overall weight                                                  'F'    [-0.412183314562,1.73373699188]
res_wgt                       res_wgt                       res_wgt                       Mass resolution weight                                          'F'    [0.020715624094,1.94245529175]
dimu_mass                     dimu_mass                     dimu_mass                     mass(#mu#mu)                  GeV                               'F'    [105.025375366,159.997497559]
nEles                         nEles                         nEles                         Number of electrons                                             'F'    [0,1]


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDTG_AWB_liteNode
   
#ifndef BDTG_AWB_liteNode__def
#define BDTG_AWB_liteNode__def
   
class BDTG_AWB_liteNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDTG_AWB_liteNode ( BDTG_AWB_liteNode* left,BDTG_AWB_liteNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDTG_AWB_liteNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDTG_AWB_liteNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDTG_AWB_liteNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDTG_AWB_liteNode*   fLeft;     // pointer to the left daughter node
   BDTG_AWB_liteNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDTG_AWB_liteNode::~BDTG_AWB_liteNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDTG_AWB_liteNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDTG_AWB_liteNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDTG_AWB_lite : public IClassifierReader {

 public:

   // constructor
   ReadBDTG_AWB_lite( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDTG_AWB_lite" ),
        fNvars( 18 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "H_pair_pt", "OS_pair_mass", "nEles", "muH1_eta_abs", "muH2_eta_abs", "muSS_muOS_dR", "muSS_OS_pair_dR", "lep_pt", "muSS_pt", "nJetsCent", "nJetsCent30", "nJetsCent40", "nBJetsLoose", "nBJetsMed", "lep_MET_MT", "lep_MHT_MT", "muSS_MET_MT", "muSS_MHT_MT" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;
      fVmin[10] = 0;
      fVmax[10] = 0;
      fVmin[11] = 0;
      fVmax[11] = 0;
      fVmin[12] = 0;
      fVmax[12] = 0;
      fVmin[13] = 0;
      fVmax[13] = 0;
      fVmin[14] = 0;
      fVmax[14] = 0;
      fVmin[15] = 0;
      fVmax[15] = 0;
      fVmin[16] = 0;
      fVmax[16] = 0;
      fVmin[17] = 0;
      fVmax[17] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'I';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'I';
      fType[10] = 'I';
      fType[11] = 'I';
      fType[12] = 'I';
      fType[13] = 'I';
      fType[14] = 'F';
      fType[15] = 'F';
      fType[16] = 'F';
      fType[17] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDTG_AWB_lite() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[18];
   double fVmax[18];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[18];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDTG_AWB_liteNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDTG_AWB_lite::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDTG_AWB_liteNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDTG_AWB_liteNode*)current->GetRight();
         else current=(BDTG_AWB_liteNode*)current->GetLeft();
      }
      myMVA += current->GetResponse();
   }
   return 2.0/(1.0+exp(-2.0*myMVA))-1.0;
};

void ReadBDTG_AWB_lite::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.477988,-0.00440234) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.228326,-0.0543349) , 
5, 1.9708, 1, 0, 0.280882,-0.219118) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.756978,0.0513955) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.58303,0.016606) , 
5, 2.30697, 1, 0, 0.668413,0.168413) , 
10, 3, 1, 0, 0.513846,0.0141485)    );
  // itree = 1
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.577841,0.0160087) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.231642,-0.0488258) , 
5, 1.77732, 1, 0, 0.276607,-0.201456) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.690909,0.0347395) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.479035,-0.00754017) , 
14, 104.147, 1, 0, 0.648181,0.130864) , 
10, 3, 1, 0, 0.501037,-0.000215304)    );
  // itree = 2
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.212446,-0.0493062) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.398186,-0.012592) , 
9, 3, 1, 0, 0.290959,-0.167332) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.698575,0.0333929) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.394746,-0.0236253) , 
14, 135.08, 1, 0, 0.66999,0.139446) , 
10, 3, 1, 0, 0.520496,0.0186897)    );
  // itree = 3
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.137067,-0.0609244) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.335833,-0.0222878) , 
10, 2, 1, 0, 0.252684,-0.183337) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.688588,0.0288735) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.533212,-0.00195072) , 
3, 1.14265, 1, 0, 0.647886,0.103003) , 
10, 3, 1, 0, 0.485003,-0.0168456)    );
  // itree = 4
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.576401,0.0148289) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.265279,-0.0362462) , 
5, 1.79825, 1, 0, 0.314925,-0.136396) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.824111,0.0533245) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.60882,0.014257) , 
5, 1.7454, 1, 0, 0.660736,0.11656) , 
9, 4, 1, 0, 0.501609,0.000156253)    );
  // itree = 5
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.60663,0.0187724) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.277005,-0.0319263) , 
5, 1.76112, 1, 0, 0.32526,-0.117918) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.699903,0.0280096) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.444633,-0.0156248) , 
14, 117.55, 1, 0, 0.665436,0.107997) , 
9, 4, 1, 0, 0.509609,0.00480466)    );
  // itree = 6
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.417919,-0.00950288) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.212522,-0.0407786) , 
5, 2.45204, 1, 0, 0.299847,-0.131298) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.72261,0.031097) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.560075,0.000732717) , 
3, 0.913948, 1, 0, 0.66265,0.0965833) , 
9, 4, 1, 0, 0.491118,-0.0111848)    );
  // itree = 7
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.528554,0.00631108) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.283718,-0.0309316) , 
5, 2.46092, 1, 0, 0.392833,-0.0677625) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.874641,0.0549621) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.707056,0.0253862) , 
5, 1.54485, 1, 0, 0.740357,0.150138) , 
10, 4, 1, 0, 0.508083,0.00469458)    );
  // itree = 8
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.181753,-0.0399058) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.437961,-0.00861197) , 
9, 3, 1, 0, 0.324695,-0.104358) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.634916,0.0101826) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.760454,0.0353035) , 
2, 1, 1, 0, 0.68852,0.0650894) , 
11, 3, 1, 0, 0.484017,-0.0147448)    );
  // itree = 9
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.145975,-0.0414187) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.37525,-0.006405) , 
0, 98.6827, 1, 0, 0.204022,-0.14402) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.68339,0.0224503) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.490497,-0.00576352) , 
5, 2.54526, 1, 0, 0.602349,0.0503141) , 
9, 3, 1, 0, 0.509516,0.0050123)    );
  // itree = 10
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.220391,-0.0328204) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.491462,-0.00261412) , 
11, 2, 1, 0, 0.402106,-0.0583328) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.856008,0.0497181) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.674116,0.0146364) , 
3, 0.342722, 1, 0, 0.719026,0.109165) , 
9, 5, 1, 0, 0.495507,-0.00799083)    );
  // itree = 11
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.24132,-0.0297358) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.400368,-0.00237957) , 
7, 44.1716, 1, 0, 0.312088,-0.079612) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.691401,0.0184078) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.453921,-0.0227936) , 
3, 1.59972, 1, 0, 0.664983,0.064588) , 
9, 4, 1, 0, 0.50214,-0.00149003)    );
  // itree = 12
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.216628,-0.0290955) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.427376,0.00873107) , 
1, 121.94, 1, 0, 0.270054,-0.0859028) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.723497,0.0252198) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.507496,-0.0159811) , 
4, 1.71416, 1, 0, 0.695567,0.0933146) , 
10, 3, 1, 0, 0.518427,0.0189827)    );
  // itree = 13
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.639222,0.00660853) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.777548,0.0377399) , 
17, 83.7122, 1, 0, 0.726641,0.120569) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.342602,-0.017818) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.696814,0.0164459) , 
9, 5, 1, 0, 0.435837,-0.0393501) , 
5, 1.86308, 1, 0, 0.506454,-0.000491172)    );
  // itree = 14
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.432081,0.00758619) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.2104,-0.0267201) , 
6, 2.16652, 1, 0, 0.264166,-0.0784072) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.698512,0.0166607) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.434911,-0.0256706) , 
14, 126.929, 1, 0, 0.670256,0.055262) , 
10, 3, 1, 0, 0.501861,-0.000190523)    );
  // itree = 15
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.262583,-0.0255773) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.431362,0.00083142) , 
1, 97.6436, 1, 0, 0.334409,-0.0621615) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.715423,0.0169354) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.527255,-0.0168358) , 
4, 1.59999, 1, 0, 0.68558,0.0521005) , 
11, 3, 1, 0, 0.491179,-0.0106213)    );
  // itree = 16
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.165809,-0.0308896) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.602333,0.0100049) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.394225,-0.020776) , 
3, 1.48567, 1, 0, 0.569831,0.0232664) , 
10, 2, 1, 0, 0.506366,0.000767021)    );
  // itree = 17
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.645489,0.0140325) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.34082,-0.0165363) , 
5, 1.75383, 1, 0, 0.393019,-0.0493363) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.713429,0.0135244) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.865127,0.0445814) , 
16, 119.515, 1, 0, 0.758353,0.0996811) , 
9, 5, 1, 0, 0.496165,-0.00727698)    );
  // itree = 18
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.280913,-0.0130788) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.160784,-0.034833) , 
3, 0.685719, 1, 0, 0.204042,-0.108354) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.620497,0.010702) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.339417,-0.0319478) , 
3, 1.71408, 1, 0, 0.592756,0.0287027) , 
11, 2, 1, 0, 0.486265,-0.00855596)    );
  // itree = 19
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.417419,-0.0137217) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.608671,0.0174033) , 
1, 105.208, 1, 0, 0.452292,-0.034386) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.490684,0.000436905) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.919536,0.0551377) , 
9, 5, 1, 0, 0.615635,0.0706494) , 
1, 134.337, 1, 0, 0.496414,-0.00626431)    );
  // itree = 20
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.29034,-0.0200246) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.435693,0.00696928) , 
17, 128.564, 1, 0, 0.322858,-0.059872) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.761745,0.0215261) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.613437,-0.00350845) , 
3, 0.685684, 1, 0, 0.68599,0.0374412) , 
11, 3, 1, 0, 0.482648,-0.0171018)    );
  // itree = 21
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.207649,-0.0175883) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.138537,-0.0325461) , 
3, 0.914221, 1, 0, 0.174817,-0.093964) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.636981,0.0119387) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.355999,-0.0336729) , 
15, 143.441, 1, 0, 0.613513,0.0358824) , 
9, 3, 1, 0, 0.498822,0.00194129)    );
  // itree = 22
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.596975,0.00684325) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.799428,0.0428259) , 
7, 106.022, 1, 0, 0.621677,0.0484664) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.278547,-0.0201416) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.684559,0.00860489) , 
9, 5, 1, 0, 0.369598,-0.0584431) , 
5, 2.54456, 1, 0, 0.505528,9.67743e-05)    );
  // itree = 23
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.431563,-0.0090069) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.634563,0.0186006) , 
7, 44.6883, 1, 0, 0.523047,0.0152732) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.337385,-0.0262706) , 
14, 127.97, 1, 0, 0.501412,-0.000354786)    );
  // itree = 24
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.222869,-0.0187588) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.628529,0.0101695) , 
11, 2, 1, 0, 0.525043,0.0147106) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.485713,-0.00739518) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.194755,-0.0420169) , 
6, 2.14621, 1, 0, 0.279556,-0.132086) , 
14, 117.546, 1, 0, 0.480472,-0.0120996)    );
  // itree = 25
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.27236,-0.0171097) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.475136,0.0145665) , 
7, 58.0104, 1, 0, 0.332694,-0.0296745) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.687527,0.00656126) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.800547,0.0297792) , 
2, 1, 1, 0, 0.736849,0.0553272) , 
11, 3, 1, 0, 0.506903,0.0146175)    );
  // itree = 26
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.188677,-0.016148) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.640089,0.0117045) , 
9, 3, 1, 0, 0.526853,0.0242227) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.26229,-0.0433974) , 
15, 154.872, 1, 0, 0.506294,0.00678565)    );
  // itree = 27
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.355921,-0.0292976) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.465973,0.000736114) , 
15, 51.6252, 1, 0, 0.417374,-0.0513097) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.636747,0.015511) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.441509,-0.0144977) , 
6, 3.11041, 1, 0, 0.603204,0.0441103) , 
1, 97.6395, 1, 0, 0.501879,-0.00791799)    );
  // itree = 28
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.359651,-0.0220022) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.528113,0.00695382) , 
7, 34.6395, 1, 0, 0.429288,-0.0404368) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.549311,0.00581114) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.870967,0.0379395) , 
9, 6, 1, 0, 0.596447,0.0443488) , 
1, 92.4933, 1, 0, 0.5111,0.000432412)    );
  // itree = 29
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.304021,-0.0282892) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.502909,0.00239425) , 
7, 23.7239, 1, 0, 0.433684,-0.0324261) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.698283,0.0231357) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.414184,-0.0103697) , 
15, 108.401, 1, 0, 0.60186,0.0489356) , 
7, 58.0098, 1, 0, 0.492792,-0.00383017)    );
  // itree = 30
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.756301,0.0287288) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.560358,-0.00156489) , 
4, 0.914012, 1, 0, 0.66692,0.062284) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.458981,-0.00447936) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.252132,-0.031621) , 
14, 106.633, 1, 0, 0.412885,-0.0432778) , 
6, 2.08672, 1, 0, 0.493946,-0.00959371)    );
  // itree = 31
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.364126,-0.0205175) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.526607,0.0062305) , 
7, 29.3364, 1, 0, 0.439832,-0.0324619) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.673562,0.0236283) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.317114,-0.0209891) , 
14, 146.131, 1, 0, 0.609488,0.0628592) , 
7, 50.5989, 1, 0, 0.512224,0.00821153)    );
  // itree = 32
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.363104,-0.0195273) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.498752,0.00657678) , 
2, 1, 1, 0, 0.418009,-0.025197) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.632318,0.0128562) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.439932,-0.0132925) , 
4, 1.71429, 1, 0, 0.605853,0.0376923) , 
1, 97.6484, 1, 0, 0.503944,-0.00227612)    );
  // itree = 33
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.585238,0.0110544) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.406972,-0.012556) , 
3, 0.914253, 1, 0, 0.512655,0.00534884) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.272834,-0.0331911) , 
15, 143.44, 1, 0, 0.490355,-0.00863491)    );
  // itree = 34
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.426926,-0.00880444) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.609366,0.00920923) , 
1, 92.4933, 1, 0, 0.515033,-0.000365975) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.272083,-0.0311178) , 
3, 1.71426, 1, 0, 0.48965,-0.0136337)    );
  // itree = 35
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.776356,0.0223759) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.491718,-7.89422e-05) , 
5, 1.61444, 1, 0, 0.541878,0.0152384) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.293549,-0.025964) , 
5, 3.1986, 1, 0, 0.516409,0.00307195)    );
  // itree = 36
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.245779,-0.0171527) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.435524,0.00185021) , 
1, 97.6586, 1, 0, 0.322656,-0.0354862) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.660653,0.000944142) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.778456,0.0197992) , 
2, 1, 1, 0, 0.711421,0.0262168) , 
11, 3, 1, 0, 0.490048,-0.00452835)    );
  // itree = 37
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.460865,-0.0101901) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.551794,0.00739724) , 
15, 51.2084, 1, 0, 0.512965,0.000127532) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.259846,-0.0298807) , 
15, 153.676, 1, 0, 0.49278,-0.00976876)    );
  // itree = 38
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.362014,-0.0114544) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.603836,0.00552629) , 
12, 2, 1, 0, 0.511677,-0.00302032) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.271337,-0.0315484) , 
15, 154.878, 1, 0, 0.493716,-0.0128812)    );
  // itree = 39
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.560623,0.00786564) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.370734,-0.0201312) , 
4, 1.71426, 1, 0, 0.533497,0.0150138) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.292545,-0.0226287) , 
15, 129.174, 1, 0, 0.501054,0.000397294)    );
  // itree = 40
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.637766,0.0153196) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.51891,0.000897889) , 
4, 0.91426, 1, 0, 0.585536,0.035451) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.333949,-0.0245488) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.432166,-0.00408005) , 
15, 40.329, 1, 0, 0.399861,-0.0438293) , 
3, 0.914284, 1, 0, 0.508664,0.00262784)    );
  // itree = 41
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.532741,0.00480279) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.279813,-0.0225505) , 
15, 153.678, 1, 0, 0.513261,0.0104465) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.283412,-0.0322601) , 
4, 2.05706, 1, 0, 0.500361,0.00241868)    );
  // itree = 42
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.711635,0.0196668) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.343249,-0.00783406) , 
5, 1.55458, 1, 0, 0.381502,-0.0191598) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.64456,-0.00338566) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.80186,0.0206843) , 
1, 64.0006, 1, 0, 0.757324,0.0524685) , 
10, 4, 1, 0, 0.499646,0.00379282)    );
  // itree = 43
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.425808,-0.00827279) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.592963,0.00788045) , 
13, 2, 1, 0, 0.483023,-0.00743657) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.869817,0.0473815) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.540764,0.0102487) , 
5, 1.70621, 1, 0, 0.669342,0.097963) , 
17, 145.954, 1, 0, 0.516388,0.00907024)    );
  // itree = 44
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.450767,-0.000280679) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.647007,0.0134614) , 
1, 97.6395, 1, 0, 0.540687,0.0236136) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.305233,-0.0263625) , 
4, 1.94286, 1, 0, 0.520649,0.0124749)    );
  // itree = 45
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.864976,0.0351958) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.550339,0.00487386) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.406306,-0.0106162) , 
3, 0.685631, 1, 0, 0.472666,-0.0140897) , 
5, 1.27381, 1, 0, 0.500041,-0.0044736)    );
  // itree = 46
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.440739,-0.00381695) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.645717,0.0140836) , 
1, 109.872, 1, 0, 0.511625,0.00948746) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.488758,-0.0345554) , 
1, 268.914, 1, 0, 0.510398,0.00180275)    );
  // itree = 47
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.29743,-0.00745633) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.72254,0.0108082) , 
9, 4, 1, 0, 0.514874,0.00836391) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.283213,-0.0235754) , 
15, 143.617, 1, 0, 0.493453,-0.00140008)    );
  // itree = 48
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.652557,0.0253779) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.342584,-0.0171519) , 
3, 1.37137, 1, 0, 0.583204,0.0597169) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.441913,-0.0103524) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.581504,0.00695188) , 
17, 128.564, 1, 0, 0.474528,-0.0251579) , 
4, 0.571439, 1, 0, 0.512195,0.00425949)    );
  // itree = 49
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.530906,-0.00615853) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.353279,-0.0226819) , 
3, 0.914186, 1, 0, 0.456751,-0.0508342) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.539911,0.00863977) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.508243,-0.0221349) , 
1, 195.502, 1, 0, 0.535339,0.016371) , 
15, 54.2006, 1, 0, 0.501144,-0.0128714)    );
   return;
};
 
// Clean up
inline void ReadBDTG_AWB_lite::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDTG_AWB_lite::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
